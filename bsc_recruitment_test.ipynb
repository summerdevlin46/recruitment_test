{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMAWFTRRGYCaa7sOaHNEBTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdae6812242242ddb245ddf6f12e9a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a9781b987fe4b47b6f3587e75446e24",
              "IPY_MODEL_f315e6ffd6f7479f9b413414b3aa66a6",
              "IPY_MODEL_b0bc553bdbf44bed8ee7a4b487451b4b"
            ],
            "layout": "IPY_MODEL_56fdedbfd10a4b59a095308407366643"
          }
        },
        "5a9781b987fe4b47b6f3587e75446e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554a89277d3043d68d9b06fa38245c24",
            "placeholder": "​",
            "style": "IPY_MODEL_35a600674e0f446eb9b353c2c6481581",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f315e6ffd6f7479f9b413414b3aa66a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8080aeb4ec9462e94dc9b7035a9bf04",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0165c1007b224108ad38f6d7408a4036",
            "value": 2
          }
        },
        "b0bc553bdbf44bed8ee7a4b487451b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bab08a1f34a477a9022f4da601bd177",
            "placeholder": "​",
            "style": "IPY_MODEL_a2952d2dc2c34d3a8810053c96466b1f",
            "value": " 2/2 [00:02&lt;00:00,  1.22s/it]"
          }
        },
        "56fdedbfd10a4b59a095308407366643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554a89277d3043d68d9b06fa38245c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a600674e0f446eb9b353c2c6481581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8080aeb4ec9462e94dc9b7035a9bf04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0165c1007b224108ad38f6d7408a4036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bab08a1f34a477a9022f4da601bd177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2952d2dc2c34d3a8810053c96466b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/summerdevlin46/recruitment_test/blob/main/bsc_recruitment_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BSC Recruitment Test"
      ],
      "metadata": {
        "id": "8sNEi4utMGhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up environment"
      ],
      "metadata": {
        "id": "zlSrG5wZMWWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNWWWiRBVmUj",
        "outputId": "afc09e56-0bba-4cc7-b67a-d3cca0adcd6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'recruitment_test' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "  !git clone https://github.com/summerdevlin46/recruitment_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "access_token_read = userdata.get('HF_TOKEN')\n",
        "\n",
        "login(token = access_token_read)"
      ],
      "metadata": {
        "id": "8c4XQGhMgj9m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON data\n",
        "with open(\"recruitment_test/data/articles.json\", \"r\") as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "1ZvXUlzQXQIf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing JSON Files"
      ],
      "metadata": {
        "id": "DpKhhWPoMgTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I removed any entries that contained null for each value, which left us with 36 entries containing usable data."
      ],
      "metadata": {
        "id": "bHwv2jmDMgRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out the entries with all null values except for pmcid\n",
        "filtered_articles = [entry for entry in data if any(value is not None for key, value in entry.items() if key != 'pmcid')]\n",
        "\n",
        "# Print filtered data\n",
        "#print(json.dumps(filtered_articles, indent=4))\n",
        "\n",
        "# Number of entries after filtering\n",
        "#print(\"Number of entries after filtering:\", len(filtered_articles))\n"
      ],
      "metadata": {
        "id": "dYIyr73Hji_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LLM and Prompting"
      ],
      "metadata": {
        "id": "AMAMtEI0M8oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to use an Instruct model to do the data extraction pipeline. However, a NER pipline could also be used to complete this task"
      ],
      "metadata": {
        "id": "dLRc-UmNEfmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set Device to CPU if GPU is out of RAM\n",
        "\n",
        "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"   # Uses more GPU RAM\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"        # Uses less GPU RAM\n",
        "# model_id = \"meta-llama/Llama-3.2-1B-Instruct\"        # Uses the least GPU RAM\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map='auto',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "cdae6812242242ddb245ddf6f12e9a8a",
            "5a9781b987fe4b47b6f3587e75446e24",
            "f315e6ffd6f7479f9b413414b3aa66a6",
            "b0bc553bdbf44bed8ee7a4b487451b4b",
            "56fdedbfd10a4b59a095308407366643",
            "554a89277d3043d68d9b06fa38245c24",
            "35a600674e0f446eb9b353c2c6481581",
            "e8080aeb4ec9462e94dc9b7035a9bf04",
            "0165c1007b224108ad38f6d7408a4036",
            "0bab08a1f34a477a9022f4da601bd177",
            "a2952d2dc2c34d3a8810053c96466b1f"
          ]
        },
        "id": "Zg2r5DBJYHp9",
        "outputId": "5c76bfb8-8c76-4ae4-e362-e78284db6ddd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdae6812242242ddb245ddf6f12e9a8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process a single article and extract relevant information\n",
        "def extract_information_from_article(article):\n",
        "    # Combine relevant fields into a single text input\n",
        "    article_content = (\n",
        "        f\"Abstract: {article.get('abstract', 'Not available')}\\n\"\n",
        "        f\"Introduction: {article.get('intro', 'Not available')}\\n\"\n",
        "        f\"Methods: {article.get('method', 'Not available')}\\n\"\n",
        "        f\"Subjects: {article.get('subjects', 'Not available')}\\n\"\n",
        "        f\"Results: {article.get('results', 'Not available')}\\n\"\n",
        "        f\"Discussion: {article.get('discussion', 'Not available')}\\n\"\n",
        "        f\"Conclusion: {article.get('conclusion', 'Not available')}\\n\"\n",
        "    )\n",
        "\n",
        "    # Define the prompt for extracting information\n",
        "    # Prompt Engineering Reasoning:\n",
        "    # After experimenting with multiple prompting approaches, this approach consistently produced the best results.\n",
        "    #\n",
        "    # Key Design Choices:\n",
        "    # 1. Role Specification: Clearly defining the LLM's role as an \"assistant trained to extract structured data\"\n",
        "    #    improves accuracy and consistency in extraction.\n",
        "    # 2. JSON Format Enforcement: The output is explicitly structured in JSON, ensuring machine-readable and\n",
        "    #    structured responses. If any information is missing, it is assigned a `null` value to maintain consistency.\n",
        "    # 3. Field Definition: Each field is clearly specified, detailing the type of information expected.\n",
        "    # 4. Flexibility in Study Design: Initially, a stricter JSON structure was enforced, but due to variability in\n",
        "    #    research methodologies (e.g., some studies not having an experimental-control group setup), the prompt was\n",
        "    #    adjusted to allow for different study designs. This ensures broader applicability across various scientific articles.\n",
        "    # 5. Changes to patient origin: Seperated categories into study site and patient demographics to provide more accurate\n",
        "    #    information.\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "You are an assistant trained to extract structured data from the scientific article provided.\n",
        "Extract the following information fields and return the output in JSON. If some information is missing, you respond with null.\n",
        "1. disease_condition: Studied disease condition, health condition, disorder, syndrome, etc.\n",
        "2. total_patients: Total number of patients\n",
        "3. case_group_patients: Number of patients in experimental groups\n",
        "4. control_group_patients: Number of patients in control groups\n",
        "5. patient_sex: Sex of the patients\n",
        "7. patient_demographics: demographics of the patients\n",
        "8. study_site: location or place or hospital of study conducted\n",
        "\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\" Scientific article:\n",
        "{article_content}\n",
        "\"\"\"\n",
        "    # Configure the messages for the LLM\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=500,\n",
        ")\n",
        "    return outputs[0][\"generated_text\"][-1]['content']"
      ],
      "metadata": {
        "id": "7E0JhYpxXdsN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processes the articles and saves extracted information"
      ],
      "metadata": {
        "id": "E6EhRT7eOAPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is to provide the output in a similar JSON format as the original data provided."
      ],
      "metadata": {
        "id": "RlV2IfV4Df0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Formats extracted information into the correct format and return it in json format\n",
        "def format_json(pmcid, content):\n",
        "\n",
        "  extracted_info = {}\n",
        "  assistant_content = content\n",
        "\n",
        "  # Look for the part of the string between the triple backticks\n",
        "  if \"```\" in assistant_content:\n",
        "      # Split based on the '```' markers\n",
        "      parts = assistant_content.split('```')\n",
        "      if len(parts) > 1:\n",
        "          # The second part should be the JSON content between the backticks\n",
        "          json_content = parts[1].strip()  # Strip out unnecessary spaces/newlines\n",
        "          try:\n",
        "              # Parse the JSON content\n",
        "              extracted_json = json.loads(json_content)\n",
        "              extracted_info = extracted_json  # Store the extracted content\n",
        "          except json.JSONDecodeError:\n",
        "              # print(f\"Error decoding JSON for pmcid: {pmcid}\")\n",
        "              return 0, None\n",
        "\n",
        "  return 1, {'pmcid':pmcid, 'extracted_info':extracted_info}"
      ],
      "metadata": {
        "id": "XaXXKZZoCogA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code processes a dataset of articles by extracting relevant information from each one, validating the extracted data, and retrying up to five times if errors are found. Successfully processed articles are stored in a results list, while errors are logged. Finally, the extracted information is saved as a JSON file at a specified location."
      ],
      "metadata": {
        "id": "tN8z_1uLO-r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Process all articles in the dataset\n",
        "results = []\n",
        "\n",
        "for article in filtered_articles:\n",
        "    attempts = 0\n",
        "    content = extract_information_from_article(article)\n",
        "\n",
        "    # Checks for errors and sends back to LLM to reprocess if error is found\n",
        "    while attempts < 5:\n",
        "        check, formatted_extracted_info = format_json(article['pmcid'], content)\n",
        "        if check == 1:\n",
        "            results.append(formatted_extracted_info)\n",
        "            print(f\"PROCESSED article with PMCID: {article['pmcid']}\")\n",
        "            break\n",
        "        # Re-extract content only if necessary\n",
        "        content = extract_information_from_article(article)\n",
        "        attempts += 1\n",
        "    else:\n",
        "        print(f\"ERROR processing article with PMCID: {article['pmcid']}\\nCONTENT:{content}\\n\")\n",
        "\n",
        "# Save the results to a JSON file\n",
        "output_path = Path(\"/content/recruitment_test/data/extracted_info.json\")\n",
        "output_path.write_text(json.dumps(results, indent=4))\n",
        "\n",
        "print(f\"Extraction complete. Results saved to {output_path}.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hpomkm8vmKKQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}